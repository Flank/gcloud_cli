
.TH "GCLOUD_ALPHA_ML\-ENGINE_MODELS_GET\-IAM\-POLICY" 1



.SH "NAME"
.HP
gcloud alpha ml\-engine models get\-iam\-policy \- get the IAM policy for a model



.SH "SYNOPSIS"
.HP
\f5gcloud alpha ml\-engine models get\-iam\-policy\fR \fIMODEL\fR [\fB\-\-region\fR=\fIREGION\fR] [\fB\-\-filter\fR=\fIEXPRESSION\fR] [\fB\-\-limit\fR=\fILIMIT\fR] [\fB\-\-page\-size\fR=\fIPAGE_SIZE\fR] [\fB\-\-sort\-by\fR=[\fIFIELD\fR,...]] [\fIGCLOUD_WIDE_FLAG\ ...\fR]



.SH "DESCRIPTION"

\fB(ALPHA)\fR Gets the IAM policy for the given model.

Returns an empty policy if the resource does not have a policy set.



.SH "POSITIONAL ARGUMENTS"

.RS 2m
.TP 2m

Model resource \- The AI Platform model to set IAM policy for. This represents a
Cloud resource. (NOTE) Some attributes are not given arguments in this group but
can be set in other ways. To set the [project] attribute: provide the argument
[model] on the command line with a fully specified name; provide the argument
[\-\-project] on the command line; set the property [core/project]. This must be
specified.

.RS 2m
.TP 2m
\fIMODEL\fR
ID of the model or fully qualified identifier for the model.


.RE
.RE
.sp

.SH "FLAGS"

.RS 2m
.TP 2m
\fB\-\-region\fR=\fIREGION\fR
Google Cloud region of the regional endpoint to use for this command. If
unspecified, the command uses the global endpoint of the AI Platform Training
and Prediction API.

Learn more about regional endpoints and see a list of available regions:
https://cloud.google.com/ai\-platform/prediction/docs/regional\-endpoints

\fIREGION\fR must be one of: \fBasia\-east1\fR, \fBeurope\-west4\fR,
\fBus\-central1\fR.


.RE
.sp

.SH "LIST COMMAND FLAGS"

.RS 2m
.TP 2m
\fB\-\-filter\fR=\fIEXPRESSION\fR
Apply a Boolean filter \fIEXPRESSION\fR to each resource item to be listed. If
the expression evaluates \f5True\fR, then that item is listed. For more details
and examples of filter expressions, run $ gcloud topic filters. This flag
interacts with other flags that are applied in this order: \fB\-\-flatten\fR,
\fB\-\-sort\-by\fR, \fB\-\-filter\fR, \fB\-\-limit\fR.

.TP 2m
\fB\-\-limit\fR=\fILIMIT\fR
Maximum number of resources to list. The default is \fBunlimited\fR. This flag
interacts with other flags that are applied in this order: \fB\-\-flatten\fR,
\fB\-\-sort\-by\fR, \fB\-\-filter\fR, \fB\-\-limit\fR.

.TP 2m
\fB\-\-page\-size\fR=\fIPAGE_SIZE\fR
Some services group resource list output into pages. This flag specifies the
maximum number of resources per page. The default is determined by the service
if it supports paging, otherwise it is \fBunlimited\fR (no paging). Paging may
be applied before or after \fB\-\-filter\fR and \fB\-\-limit\fR depending on the
service.

.TP 2m
\fB\-\-sort\-by\fR=[\fIFIELD\fR,...]
Comma\-separated list of resource field key names to sort by. The default order
is ascending. Prefix a field with ``~'' for descending order on that field. This
flag interacts with other flags that are applied in this order:
\fB\-\-flatten\fR, \fB\-\-sort\-by\fR, \fB\-\-filter\fR, \fB\-\-limit\fR.


.RE
.sp

.SH "GCLOUD WIDE FLAGS"

These flags are available to all commands: \-\-account, \-\-billing\-project,
\-\-configuration, \-\-flags\-file, \-\-flatten, \-\-format, \-\-help,
\-\-impersonate\-service\-account, \-\-log\-http, \-\-project, \-\-quiet,
\-\-trace\-token, \-\-user\-output\-enabled, \-\-verbosity.

Run \fB$ gcloud help\fR for details.



.SH "EXAMPLES"

The following command gets the IAM policy for the model \f5my_model\fR:

.RS 2m
$ gcloud alpha ml\-engine models get\-iam\-policy my_model
.RE



.SH "NOTES"

This command is currently in ALPHA and may change without notice. If this
command fails with API permission errors despite specifying the right project,
you may be trying to access an API with an invitation\-only early access
whitelist. These variants are also available:

.RS 2m
$ gcloud ml\-engine models get\-iam\-policy
$ gcloud beta ml\-engine models get\-iam\-policy
.RE

