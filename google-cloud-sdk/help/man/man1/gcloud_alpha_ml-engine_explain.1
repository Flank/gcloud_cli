
.TH "GCLOUD_ALPHA_ML\-ENGINE_EXPLAIN" 1



.SH "NAME"
.HP
gcloud alpha ml\-engine explain \- run AI Platform explanation



.SH "SYNOPSIS"
.HP
\f5gcloud alpha ml\-engine explain\fR \fB\-\-model\fR=\fIMODEL\fR (\fB\-\-json\-instances\fR=\fIJSON_INSTANCES\fR\ |\ \fB\-\-json\-request\fR=\fIJSON_REQUEST\fR\ |\ \fB\-\-text\-instances\fR=\fITEXT_INSTANCES\fR) [\fB\-\-region\fR=\fIREGION\fR] [\fB\-\-version\fR=\fIVERSION\fR] [\fIGCLOUD_WIDE_FLAG\ ...\fR]



.SH "DESCRIPTION"

\fB(ALPHA)\fR \f5gcloud alpha ml\-engine explain\fR sends an explain request to
AI Platform for the given instances. This command will read up to 100 instances,
though the service itself will accept instances up to the payload limit size
(currently, 1.5MB).



.SH "REQUIRED FLAGS"

.RS 2m
.TP 2m
\fB\-\-model\fR=\fIMODEL\fR
Name of the model.

.TP 2m

Exactly one of these must be specified:

.RS 2m
.TP 2m
\fB\-\-json\-instances\fR=\fIJSON_INSTANCES\fR
Path to a local file from which instances are read. Instances are in JSON
format; newline delimited.

An example of the JSON instances file:

.RS 2m
{"images": [0.0, ..., 0.1], "key": 3}
{"images": [0.0, ..., 0.1], "key": 2}
...
.RE

This flag accepts "\-" for stdin.

.TP 2m
\fB\-\-json\-request\fR=\fIJSON_REQUEST\fR
Path to a local file containing the body of JSON request.

An example of a JSON request:

.RS 2m
{
  "instances": [
    {"x": [1, 2], "y": [3, 4]},
    {"x": [\-1, \-2], "y": [\-3, \-4]}
  ]
}
.RE

This flag accepts "\-" for stdin.

.TP 2m
\fB\-\-text\-instances\fR=\fITEXT_INSTANCES\fR
Path to a local file from which instances are read. Instances are in UTF\-8
encoded text format; newline delimited.

An example of the text instances file:

.RS 2m
107,4.9,2.5,4.5,1.7
100,5.7,2.8,4.1,1.3
...
.RE

This flag accepts "\-" for stdin.


.RE
.RE
.sp

.SH "OPTIONAL FLAGS"

.RS 2m
.TP 2m
\fB\-\-region\fR=\fIREGION\fR
Google Cloud region of the regional endpoint to use for this command. If
unspecified, the command uses the global endpoint of the AI Platform Training
and Prediction API.

Learn more about regional endpoints and see a list of available regions:
https://cloud.google.com/ai\-platform/prediction/docs/regional\-endpoints

\fIREGION\fR must be one of: \fBasia\-east1\fR, \fBeurope\-west4\fR,
\fBus\-central1\fR.

.TP 2m
\fB\-\-version\fR=\fIVERSION\fR
Model version to be used.

If unspecified, the default version of the model will be used. To list model
versions run

.RS 2m
$ gcloud alpha ml\-engine versions list
.RE


.RE
.sp

.SH "GCLOUD WIDE FLAGS"

These flags are available to all commands: \-\-account, \-\-billing\-project,
\-\-configuration, \-\-flags\-file, \-\-flatten, \-\-format, \-\-help,
\-\-impersonate\-service\-account, \-\-log\-http, \-\-project, \-\-quiet,
\-\-trace\-token, \-\-user\-output\-enabled, \-\-verbosity.

Run \fB$ gcloud help\fR for details.



.SH "EXAMPLES"

To get explanations for an AI Platform version model with the version 'version'
and with the name 'model\-name', run:

.RS 2m
$ gcloud alpha ml\-engine explain explain \-\-model=model\-name \e
    \-\-version=version           \-\-json\-instances=instances.json
.RE



.SH "NOTES"

This command is currently in ALPHA and may change without notice. If this
command fails with API permission errors despite specifying the right project,
you may be trying to access an API with an invitation\-only early access
allowlist. This variant is also available:

.RS 2m
$ gcloud beta ml\-engine explain
.RE

