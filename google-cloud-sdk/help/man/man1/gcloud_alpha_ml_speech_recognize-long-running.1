
.TH "GCLOUD_ALPHA_ML_SPEECH_RECOGNIZE\-LONG\-RUNNING" 1



.SH "NAME"
.HP
gcloud alpha ml speech recognize\-long\-running \- get transcripts of longer audio from an audio file



.SH "SYNOPSIS"
.HP
\f5gcloud alpha ml speech recognize\-long\-running\fR \fIAUDIO\fR \fB\-\-language\-code\fR=\fILANGUAGE_CODE\fR [\fB\-\-additional\-language\-codes\fR=[\fILANGUAGE_CODE\fR,...]] [\fB\-\-async\fR] [\fB\-\-enable\-automatic\-punctuation\fR] [\fB\-\-encoding\fR=\fIENCODING\fR;\ default="encoding\-unspecified"] [\fB\-\-filter\-profanity\fR] [\fB\-\-hints\fR=[\fIHINTS\fR,...]] [\fB\-\-include\-word\-confidence\fR] [\fB\-\-include\-word\-time\-offsets\fR] [\fB\-\-max\-alternatives\fR=\fIMAX_ALTERNATIVES\fR;\ default=1] [\fB\-\-sample\-rate\fR=\fISAMPLE_RATE\fR] [\fB\-\-audio\-channel\-count\fR=\fIAUDIO_CHANNEL_COUNT\fR\ \fB\-\-separate\-channel\-recognition\fR] [\fB\-\-audio\-topic\fR=\fIAUDIO_TOPIC\fR\ \fB\-\-interaction\-type\fR=\fIINTERACTION_TYPE\fR\ \fB\-\-microphone\-distance\fR=\fIMICROPHONE_DISTANCE\fR\ \fB\-\-naics\-code\fR=\fINAICS_CODE\fR\ \fB\-\-original\-media\-type\fR=\fIORIGINAL_MEDIA_TYPE\fR\ \fB\-\-original\-mime\-type\fR=\fIORIGINAL_MIME_TYPE\fR\ \fB\-\-recording\-device\-name\fR=\fIRECORDING_DEVICE_NAME\fR\ \fB\-\-recording\-device\-type\fR=\fIRECORDING_DEVICE_TYPE\fR] [\fB\-\-enable\-speaker\-diarization\fR\ :\ \fB\-\-diarization\-speaker\-count\fR=\fIDIARIZATION_SPEAKER_COUNT\fR] [\fIGCLOUD_WIDE_FLAG\ ...\fR]



.SH "DESCRIPTION"

\fB(ALPHA)\fR Get a transcript of audio up to 80 minutes in length. If the audio
is under 60 seconds, you may also use \f5gcloud alpha ml speech recognize\fR to
analyze it.



.SH "POSITIONAL ARGUMENTS"

.RS 2m
.TP 2m
\fIAUDIO\fR
The location of the audio file to transcribe. Must be a local path or a Google
Cloud Storage URL (in the format gs://bucket/object).


.RE
.sp

.SH "REQUIRED FLAGS"

.RS 2m
.TP 2m
\fB\-\-language\-code\fR=\fILANGUAGE_CODE\fR
The language of the supplied audio as a BCP\-47
(https://www.rfc\-editor.org/rfc/bcp/bcp47.txt) language tag. Example: "en\-US".
See https://cloud.google.com/speech/docs/languages for a list of the currently
supported language codes.


.RE
.sp

.SH "OPTIONAL FLAGS"

.RS 2m
.TP 2m
\fB\-\-additional\-language\-codes\fR=[\fILANGUAGE_CODE\fR,...]
The BCP\-47 language tags of other languages that the speech may be in. Up to 3
can be provided.

If alternative languages are listed, recognition result will contain recognition
in the most likely language detected including the main language\-code.

.TP 2m
\fB\-\-async\fR
Return immediately, without waiting for the operation in progress to complete.

.TP 2m
\fB\-\-enable\-automatic\-punctuation\fR
Adds punctuation to recognition result hypotheses.

.TP 2m
\fB\-\-encoding\fR=\fIENCODING\fR; default="encoding\-unspecified"
The type of encoding of the file. Required if the file format is not WAV or
FLAC. \fIENCODING\fR must be one of: \fBamr\fR, \fBamr\-wb\fR,
\fBencoding\-unspecified\fR, \fBflac\fR, \fBlinear16\fR, \fBmp3\fR, \fBmulaw\fR,
\fBogg\-opus\fR, \fBspeex\-with\-header\-byte\fR, \fBwebm\-opus\fR.

.TP 2m
\fB\-\-filter\-profanity\fR
If True, the server will attempt to filter out profanities, replacing all but
the initial character in each filtered word with asterisks, e.g. \e"f**\fB\e".

.TP 2m
\fR\-\-hints\fB=[\fIHINTS\fR,...]
A list of strings containing word and phrase "hints" so that the speech
recognition is more likely to recognize them. This can be used to improve the
accuracy for specific words and phrases, for example, if specific commands are
typically spoken by the user. This can also be used to add additional words to
the vocabulary of the recognizer. See
https://cloud.google.com/speech/limits#content.

.TP 2m
\fR\-\-include\-word\-confidence\fB
Include a list of words and the confidence for those words in the top result.

.TP 2m
\fR\-\-include\-word\-time\-offsets\fB
If True, the top result includes a list of words with the start and end time
offsets (timestamps) for those words. If False, no word\-level time offset
information is returned.

.TP 2m
\fR\-\-max\-alternatives\fB=\fIMAX_ALTERNATIVES\fR; default=1
Maximum number of recognition hypotheses to be returned. The server may return
fewer than max_alternatives. Valid values are 0\-30. A value of 0 or 1 will
return a maximum of one.

.TP 2m
\fR\-\-sample\-rate\fB=\fISAMPLE_RATE\fR
The sample rate in Hertz. For best results, set the sampling rate of the audio
source to 16000 Hz. If that's not possible, use the native sample rate of the
audio source (instead of re\-sampling).

.TP 2m

Audio channel settings.

.RS 2m
.TP 2m
\fR\-\-audio\-channel\-count\fB=\fIAUDIO_CHANNEL_COUNT\fR
The number of channels in the input audio data. Set this for
separate\-channel\-recognition. Valid values are: 1)LINEAR16 and FLAC are
\f51\fR\-\f58\fR 2)OGG_OPUS are \f51\fR\-\f5254\fR 3) MULAW, AMR, AMR_WB and
SPEEX_WITH_HEADER_BYTE is only \f51\fR. This flag must be specified if any of
the other arguments in this group are specified.

.TP 2m
\fR\-\-separate\-channel\-recognition\fB
Recognition result will contain a \f5channel_tag\fR field to state which channel
that result belongs to. If this is not true, only the first channel will be
recognized. This flag must be specified if any of the other arguments in this
group are specified.

.RE
.sp
.TP 2m

Description of audio data to be recognized.

.RS 2m
.TP 2m
\fR\-\-audio\-topic\fB=\fIAUDIO_TOPIC\fR
Description of the content, e.g. "Recordings of federal supreme court hearings
from 2012".

.TP 2m
\fR\-\-interaction\-type\fB=\fIINTERACTION_TYPE\fR
Determining the interaction type in the conversation. \fIINTERACTION_TYPE\fR
must be one of:

.RS 2m
.TP 2m
\fRdictation\fB
Transcribe speech to text to create a written document, such as a text\-message,
email or report.
.TP 2m
\fRdiscussion\fB
Multiple people in a conversation or discussion.
.TP 2m
\fRphone\-call\fB
A phone\-call or video\-conference in which two or more people, who are not in
the same room, are actively participating.
.TP 2m
\fRprofessionally\-produced\fB
Professionally produced audio (eg. TV Show, Podcast).
.TP 2m
\fRvoice\-command\fB
Transcribe voice commands, such as for controlling a device.
.TP 2m
\fRvoice\-search\fB
Transcribe spoken questions and queries into text.
.TP 2m
\fRvoicemail\fB
A recorded message intended for another person to listen to.
.RE
.sp


.TP 2m
\fR\-\-microphone\-distance\fB=\fIMICROPHONE_DISTANCE\fR
The distance at which the audio device is placed to record the conversation.
\fIMICROPHONE_DISTANCE\fR must be one of:

.RS 2m
.TP 2m
\fRfarfield\fB
The speaker is more than 3 meters away from the microphone.
.TP 2m
\fRmidfield\fB
The speaker is within 3 meters of the microphone.
.TP 2m
\fRnearfield\fB
The speaker is within 1 meter of the microphone.
.RE
.sp


.TP 2m
\fR\-\-naics\-code\fB=\fINAICS_CODE\fR
The industry vertical to which this speech recognition request most closely
applies.

.TP 2m
\fR\-\-original\-media\-type\fB=\fIORIGINAL_MEDIA_TYPE\fR
The media type of the original audio conversation. \fIORIGINAL_MEDIA_TYPE\fR
must be one of:

.RS 2m
.TP 2m
\fRaudio\fB
The speech data is an audio recording.
.TP 2m
\fRvideo\fB
The speech data originally recorded on a video.
.RE
.sp


.TP 2m
\fR\-\-original\-mime\-type\fB=\fIORIGINAL_MIME_TYPE\fR
Mime type of the original audio file. Examples: \f5audio/m4a\fR,
\f5audio/mp3\fR.

.TP 2m
\fR\-\-recording\-device\-name\fB=\fIRECORDING_DEVICE_NAME\fR
The device used to make the recording. Examples: \f5Nexus 5X\fR, \f5Polycom
SoundStation IP 6000\fR

.TP 2m
\fR\-\-recording\-device\-type\fB=\fIRECORDING_DEVICE_TYPE\fR
The device type through which the original audio was recorded on.
\fIRECORDING_DEVICE_TYPE\fR must be one of:

.RS 2m
.TP 2m
\fRindoor\fB
Speech was recorded indoors.
.TP 2m
\fRoutdoor\fB
Speech was recorded outdoors.
.TP 2m
\fRpc\fB
Speech was recorded using a personal computer or tablet.
.TP 2m
\fRphone\-line\fB
Speech was recorded over a phone line.
.TP 2m
\fRsmartphone\fB
Speech was recorded on a smartphone.
.TP 2m
\fRvehicle\fB
Speech was recorded in a vehicle.
.RE
.sp


.RE
.sp
.TP 2m
\fR\-\-enable\-speaker\-diarization\fB
Enable speaker detection for each recognized word in the top alternative of the
recognition result using an integer speaker_tag provided in the WordInfo.

.TP 2m
\fR\-\-diarization\-speaker\-count\fB=\fIDIARIZATION_SPEAKER_COUNT\fR
Estimated number of speakers in the conversation being recognized.


\fR
.RE
.sp

.SH "GCLOUD WIDE FLAGS"

These flags are available to all commands: \-\-account, \-\-billing\-project,
\-\-configuration, \-\-flags\-file, \-\-flatten, \-\-format, \-\-help,
\-\-impersonate\-service\-account, \-\-log\-http, \-\-project, \-\-quiet,
\-\-trace\-token, \-\-user\-output\-enabled, \-\-verbosity.

Run \fB$ gcloud help\fR for details.



.SH "API REFERENCE"

This command uses the \fBspeech/v1p1beta1\fR API. The full documentation for
this API can be found at:
https://cloud.google.com/speech\-to\-text/docs/quickstart\-protocol



.SH "EXAMPLES"

To block the command from completing until analysis is finished, run:

.RS 2m
$ gcloud alpha ml speech recognize\-long\-running AUDIO_FILE \e
    \-\-language\-code=LANGUAGE_CODE \-\-sample\-rate=SAMPLE_RATE
.RE

You can also receive an operation as the result of the command by running:

.RS 2m
$ gcloud alpha ml speech recognize\-long\-running AUDIO_FILE \e
    \-\-language\-code=LANGUAGE_CODE \-\-sample\-rate=SAMPLE_RATE \-\-async
.RE

This will return information about an operation. To get information about the
operation, run:

.RS 2m
$ gcloud alpha ml speech operations describe OPERATION_ID
.RE

To poll the operation until it's complete, run:

.RS 2m
$ gcloud alpha ml speech operations wait OPERATION_ID
.RE



.SH "NOTES"

This command is currently in ALPHA and may change without notice. If this
command fails with API permission errors despite specifying the right project,
you may be trying to access an API with an invitation\-only early access
allowlist. These variants are also available:

.RS 2m
$ gcloud ml speech recognize\-long\-running
$ gcloud beta ml speech recognize\-long\-running
.RE

