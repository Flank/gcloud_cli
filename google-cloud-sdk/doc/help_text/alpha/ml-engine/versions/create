NAME
    gcloud alpha ml-engine versions create - create a new Cloud ML Engine
        version

SYNOPSIS
    gcloud alpha ml-engine versions create VERSION --model=MODEL
        [--accelerator=[count=COUNT],[type=TYPE]] [--async] [--config=CONFIG]
        [--description=DESCRIPTION] [--framework=FRAMEWORK]
        [--labels=[KEY=VALUE,...]] [--machine-type=MACHINE_TYPE]
        [--origin=ORIGIN] [--python-version=PYTHON_VERSION]
        [--runtime-version=RUNTIME_VERSION] [--staging-bucket=STAGING_BUCKET]
        [--model-class=MODEL_CLASS --package-uris=[PACKAGE_URI,...]]
        [GCLOUD_WIDE_FLAG ...]

DESCRIPTION
    (ALPHA) Creates a new version of a Cloud ML Engine model.

    For more details on managing ML Engine models and versions see
    https://cloud.google.com/ml-engine/docs/how-tos/managing-models-jobs

POSITIONAL ARGUMENTS
     VERSION
        Name of the model version.

REQUIRED FLAGS
     --model=MODEL
        Name of the model.

OPTIONAL FLAGS
     --accelerator=[count=COUNT],[type=TYPE]
        Manage the accelerator config for GPU serving. When deploying a model
        with the new Alpha Google Compute Engine Machine Types, a GPU
        accelerator may also be selected.

         type
            The type of the accelerator. Choices are 'nvdia-tesla-k80',
            'nvdia-tesla-p100', 'nvdia-tesla-v100' and 'nvdia-tesla-p4'.

         count
            The number of accelerators to attach to each machine running the
            job.
     --async
        Display information about the operation in progress, without waiting
        for the operation to complete.

     --config=CONFIG
        Path to a YAML configuration file containing configuration parameters
        for the Version
        (https://cloud.google.com/ml/reference/rest/v1/projects.models.versions)
        to create.

        The file is in YAML format. Note that not all attributes of a Version
        are configurable; available attributes (with example values) are:

            description: A free-form description of the version.
            deploymentUri: gs://path/to/source
            runtimeVersion: '1.0'
            manualScaling:
              nodes: 10  # The number of nodes to allocate for this model.
            autoScaling:
              minNodes: 0  # The minimum number of nodes to allocate for this model.
            labels:
              user-defined-key: user-defined-value

        The name of the version must always be specified via the required
        VERSION argument.

        Only one of manualScaling or autoScaling must be specified. If both are
        specified in same yaml file an error will be returned.

        If an option is specified both in the configuration file and via
        command line arguments, the command line arguments override the
        configuration file.

     --description=DESCRIPTION
        The description of the version.

     --framework=FRAMEWORK
        The ML framework used to train this version of the model. If not
        specified, defaults to tensorflow. FRAMEWORK must be one of:
        scikit-learn, tensorflow, xgboost.

     --labels=[KEY=VALUE,...]
        List of label KEY=VALUE pairs to add.

        Keys must start with a lowercase character and contain only hyphens
        (-), underscores (_), lowercase characters, and numbers. Values must
        contain only hyphens (-), underscores (_), lowercase characters, and
        numbers.

     --machine-type=MACHINE_TYPE
        Type of machine on which to serve the model. Currently only applies to
        online prediction. Currently supported machine_types are:

        * mls1-c1-m2 - A virtual machine with 1 core and 2 Gb RAM (default).
        * mls1-c4-m2 - A virtual machine with 4 core and 2 Gb RAM.
        * mls1-highmem-1 - A virtual machine with 1 core and 2 Gb RAM (will
          be deprecated soon).
        * mls1-highcpu-4 - A virtual machine with 4 core and 2 Gb RAM (will
          be deprecated soon).

     --origin=ORIGIN
        Location of model/ "directory" (as output by
        https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#Saver).

        This overrides deploymentUri in the --config file. If this flag is not
        passed, deploymentUri must be specified in the file from --config.

        Can be a Google Cloud Storage (gs://) path or local file path (no
        prefix). In the latter case the files will be uploaded to Google Cloud
        Storage and a --staging-bucket argument is required.

     --python-version=PYTHON_VERSION
        Version of Python used when creating the version. If not set, the
        default version is 2.7. Python 3.5 is available when runtime_version is
        set to 1.4 and above. Python 2.7 works with all supported runtime
        versions.

     --runtime-version=RUNTIME_VERSION
        Google Cloud ML Engine runtime version for this job. Defaults to a
        stable version, which is defined in documentation along with the list
        of supported versions:
        https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list

     --staging-bucket=STAGING_BUCKET
        Bucket in which to stage training archives.

        Required only if a file upload is necessary (that is, other flags
        include local paths) and no other flags implicitly specify an upload
        path.

     Configure user code in prediction. Cloud ML Engine allows a model to have
     user-provided prediction code; these options configure that code.

       --model-class=MODEL_CLASS
          The fully-qualified name of the custom Model class in the package
          provided for custom prediction.

          For example, --model-class my_package.SequenceModel.

       --package-uris=[PACKAGE_URI,...]
          Comma-separated list of Google Cloud Storage URIs (gs://...) for
          user-supplied Python packages to use.

GCLOUD WIDE FLAGS
    These flags are available to all commands: --account, --configuration,
    --flags-file, --flatten, --format, --help, --log-http, --project, --quiet,
    --trace-token, --user-output-enabled, --verbosity. Run $ gcloud help for
    details.

NOTES
    This command is currently in ALPHA and may change without notice. If this
    command fails with API permission errors despite specifying the right
    project, you will have to apply for early access and have your projects
    registered on the API whitelist to use it. To do so, contact Support at
    https://cloud.google.com/support/. These variants are also available:

        $ gcloud ml-engine versions create
        $ gcloud beta ml-engine versions create

