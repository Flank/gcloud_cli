NAME
    gcloud dataproc - create and manage Google Cloud Dataproc clusters and jobs

SYNOPSIS
    gcloud dataproc GROUP [--region=REGION] [GCLOUD_WIDE_FLAG ...]

DESCRIPTION
    The gcloud dataproc command group lets you create and manage Google Cloud
    Dataproc clusters and jobs.

    Cloud Dataproc is an Apache Hadoop, Apache Spark, Apache Pig, and Apache
    Hive service. It easily processes big datasets at low cost, creating
    managed clusters of any size that scale down once processing is complete.

    More information on Cloud Dataproc can be found here:
    https://cloud.google.com/dataproc and detailed documentation can be found
    here: https://cloud.google.com/dataproc/docs/

EXAMPLES
    To see how to create and manage clusters, run:

        $ gcloud dataproc clusters

    To see how to submit and manage jobs, run:

        $ gcloud dataproc jobs

FLAGS
     --region=REGION
        Cloud Dataproc region to use. Each Cloud Dataproc region constitutes an
        independent resource namespace constrained to deploying instances into
        Compute Engine zones inside the region. The default value of global is
        a special multi-region namespace which is capable of deploying
        instances into all Compute Engine zones globally, and is disjoint from
        other Cloud Dataproc regions. Overrides the default dataproc/region
        property value for this command invocation.

GCLOUD WIDE FLAGS
    These flags are available to all commands: --account, --configuration,
    --flatten, --format, --help, --log-http, --project, --quiet, --trace-token,
    --user-output-enabled, --verbosity. Run $ gcloud help for details.

GROUPS
    GROUP is one of the following:

     clusters
        Create and manage Google Cloud Dataproc clusters.

     jobs
        Submit and manage Google Cloud Dataproc jobs.

     operations
        View and manage Google Cloud Dataproc operations.

NOTES
    This variant is also available:

        $ gcloud beta dataproc

